{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ameya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ameya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\ameya/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:10<00:00, 4.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained model\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies the last layer to fit the number of classes in the dataset (2 for cat and dog)\n",
    "num_classes = 2\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# format for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# split dataset into training, validation, and testing sets, applying the format\n",
    "train_dataset = ImageFolder('./dataset/training_set', transform=transform)\n",
    "val_dataset = ImageFolder('./dataset/training_set', transform=transform)\n",
    "test_dataset = ImageFolder('./dataset/test_set', transform=transform)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# load the datasets into the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    # Determine whether to use GPU (if available) or CPU\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialize running loss and correct predictions count for training\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the training data loader\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move inputs and labels to the device (GPU or CPU)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Reset the gradients to zero before the backward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            outputs = model(inputs)\n",
    "            # Get the predicted class (with the highest score)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # Compute the loss between the predictions and actual labels\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "            # Perform the optimization step to update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the running loss and the number of correct predictions\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Compute average training loss and accuracy for this epoch\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "        # Set the model to evaluation mode for validation\n",
    "        model.eval()\n",
    "        # Initialize running loss and correct predictions count for validation\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Disable gradient computation for validation (saves memory and computations)\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the validation data loader\n",
    "            for inputs, labels in val_loader:\n",
    "                # Move inputs and labels to the device (GPU or CPU)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass: compute the model output\n",
    "                outputs = model(inputs)\n",
    "                # Get the predicted class (with the highest score)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                # Compute the loss between the predictions and actual labels\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accumulate the running loss and the number of correct predictions\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Compute average validation loss and accuracy for this epoch\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_corrects.float() / len(val_loader.dataset)\n",
    "\n",
    "        # Print the results for the current epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.1580, train acc: 0.9417, val loss: 0.0755, val acc: 0.9760\n",
      "Epoch [2/5], train loss: 0.0916, train acc: 0.9663, val loss: 0.0618, val acc: 0.9811\n",
      "Epoch [3/5], train loss: 0.0871, train acc: 0.9675, val loss: 0.0594, val acc: 0.9809\n",
      "Epoch [4/5], train loss: 0.0842, train acc: 0.9675, val loss: 0.0537, val acc: 0.9810\n",
      "Epoch [5/5], train loss: 0.0742, train acc: 0.9716, val loss: 0.0505, val acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per class:\n",
      "cats: 0.9800\n",
      "dogs: 0.9770\n",
      "\n",
      "Overall Accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    # Initialize dictionaries to store correct and total predictions\n",
    "    correct_pred = {classname: 0 for classname in test_loader.dataset.classes}\n",
    "    total_pred = {classname: 0 for classname in test_loader.dataset.classes}\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Track the ground truth labels and predictions\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Collect predictions and labels for metric calculations\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Update the correct and total predictions\n",
    "            for label, prediction in zip(labels, preds):\n",
    "                classname = test_loader.dataset.classes[label]\n",
    "                if label == prediction:\n",
    "                    correct_pred[classname] += 1\n",
    "                total_pred[classname] += 1\n",
    "\n",
    "    # Calculate accuracy per class\n",
    "    accuracy_per_class = {classname: correct_pred[classname] / total_pred[classname] if total_pred[classname] > 0 else 0\n",
    "                          for classname in test_loader.dataset.classes}\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print(\"Accuracy per class:\")\n",
    "    for classname, accuracy in accuracy_per_class.items():\n",
    "        print(f\"{classname}: {accuracy:.4f}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Example usage\n",
    "evaluate_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
